{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/margaridagomes/dataeng-basic-course/blob/main/spark/challenges/challenge_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# CHALLENGE 1\n",
        "##  Implement INGESTION process\n",
        "- Set up path in the \"lake\"\n",
        "  - !mkdir -p /content/lake/bronze\n",
        "\n",
        "- Read data from API https://api.carrismetropolitana.pt/\n",
        "  - Endpoints:\n",
        "    - vehicles\n",
        "    - lines\n",
        "    - municipalities\n",
        "  - Use StructFields to enforce schema\n",
        "\n",
        "- Transformations\n",
        "  - vehicles\n",
        "    - create \"date\" extracted from \"timestamp\" column (format: date - yyyy-mm-dd or yyyymmdd)\n",
        "\n",
        "- Write data as PARQUET into the BRONZE layer (/content/lake/bronze)\n",
        "  - Partition \"vehicles\" by \"date\" column\n",
        "  - Paths:\n",
        "    - vehicles - path: /content/lake/bronze/vehicles\n",
        "    - lines - path: /content/lake/bronze/lines\n",
        "    - municipalities - path: /content/lake/bronze/municipalities\n",
        "  - Make sure there is only 1 single parquet created\n",
        "  - Use overwrite as write mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "8d9e9c29-1c45-47d8-d495-a48bd4651e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up path in the \"lake\"\n",
        "!mkdir -p /content/lake/bronze\n",
        "\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "import requests\n",
        "\n",
        "class ETLFlow:\n",
        "    \"\"\"\n",
        "    Base ETL class that provides common extraction and loading functionality.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        self.spark = spark\n",
        "\n",
        "    def extract_from_api(self, url: str, schema: StructType = None):\n",
        "        \"\"\"\n",
        "        Extract data from a REST API endpoint and load it into a Spark DataFrame, enforcing a schema using StructType.\n",
        "        \"\"\"\n",
        "        response = requests.get(url)\n",
        "        rdd = spark.sparkContext.parallelize(response.json())\n",
        "        if schema:\n",
        "            df = spark.read.schema(schema).json(rdd)\n",
        "        else:\n",
        "            df = spark.read.json(rdd)\n",
        "        return df\n",
        "\n",
        "    def load(self, df: DataFrame, format: str, path: str, partition_column: str = None, dynamic_partition_overwrite: bool = False, **kwargs) -> None:\n",
        "        \"\"\"\n",
        "        Save the DataFrame to the specified path in the chosen format.\n",
        "        If 'partition_column' is provided, partition the data accordingly.\n",
        "        If 'dynamic_partition_overwrite' is True, only overwrite the partitions present in the DataFrame.\n",
        "        \"\"\"\n",
        "        # Set Spark configuration for dynamic/static partition overwrite mode\n",
        "        if dynamic_partition_overwrite:\n",
        "            self.spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
        "        else:\n",
        "            self.spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"static\")\n",
        "\n",
        "        # Write the DataFrame as a single parquet file, with optional partitioning\n",
        "        if partition_column:\n",
        "            df.coalesce(1).write.mode(\"overwrite\").partitionBy(partition_column).format(format).save(path)\n",
        "        else:\n",
        "            df.coalesce(1).write.mode(\"overwrite\").format(format).save(path)\n",
        "\n",
        "class ETLTask(ETLFlow):\n",
        "    \"\"\"\n",
        "    ETLTask class implements ingestion steps for vehicles, lines, and municipalities datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        self.spark = spark\n",
        "\n",
        "    def ingestion_lines(self):\n",
        "        \"\"\"\n",
        "        Extract 'lines' data from the API, enforce schema, and write as a single parquet file.\n",
        "        \"\"\"\n",
        "        # Schema definition for lines\n",
        "        lines_schema = StructType([StructField('color', StringType(), True),\n",
        "                                   StructField('facilities', ArrayType(StringType(), True), True),\n",
        "                                   StructField('id', StringType(), True),\n",
        "                                   StructField('localities', ArrayType(StringType(), True), True),\n",
        "                                   StructField('long_name', StringType(), True),\n",
        "                                   StructField('municipalities', ArrayType(StringType(), True), True),\n",
        "                                   StructField('patterns', ArrayType(StringType(), True), True),\n",
        "                                   StructField('routes', ArrayType(StringType(), True), True),\n",
        "                                   StructField('short_name', StringType(), True),\n",
        "                                   StructField('text_color', StringType(), True)])\n",
        "\n",
        "        # Ingestion\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/lines\", schema=lines_schema)\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/lines\")\n",
        "\n",
        "    def ingestion_vehicles(self):\n",
        "        \"\"\"\n",
        "        Extract 'vehicles' data from the API, enforce schema, add a partitioning 'date' column,\n",
        "        and write as a partitioned parquet file with dynamic partition overwrite enabled.\n",
        "        \"\"\"\n",
        "        # Schema definition for vehicles\n",
        "        vehicle_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                                  StructField('block_id', StringType(), True),\n",
        "                                  StructField('current_status', StringType(), True),\n",
        "                                  StructField('id', StringType(), True),\n",
        "                                  StructField('lat', FloatType(), True),\n",
        "                                  StructField('line_id', StringType(), True),\n",
        "                                  StructField('lon', FloatType(), True),\n",
        "                                  StructField('pattern_id', StringType(), True),\n",
        "                                  StructField('route_id', StringType(), True),\n",
        "                                  StructField('schedule_relationship', StringType(), True),\n",
        "                                  StructField('shift_id', StringType(), True),\n",
        "                                  StructField('speed', FloatType(), True),\n",
        "                                  StructField('stop_id', StringType(), True),\n",
        "                                  StructField('timestamp', TimestampType(), True),\n",
        "                                  StructField('trip_id', StringType(), True)])\n",
        "\n",
        "        # Ingestion\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/vehicles\", schema=vehicle_schema)\n",
        "\n",
        "        # Create \"date\" column from \"timestamp\"\n",
        "        df = df.withColumn(\"date\", F.expr(\"date(timestamp)\"))\n",
        "\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/vehicles\", partition_column=\"date\", dynamic_partition_overwrite=True)\n",
        "\n",
        "    def ingestion_municipalities(self):\n",
        "        \"\"\"\n",
        "        Extract 'municipalities' data from the API, enforce schema, and write as a single parquet file.\n",
        "        \"\"\"\n",
        "        # Schema definition for municipalities\n",
        "        municipalities_schema = StructType([StructField('district_id', StringType(), True),\n",
        "                                            StructField('district_name', StringType(), True),\n",
        "                                            StructField('id', StringType(), True),\n",
        "                                            StructField('name', StringType(), True),\n",
        "                                            StructField('prefix', StringType(), True),\n",
        "                                            StructField('region_id', StringType(), True),\n",
        "                                            StructField('region_name', StringType(), True)])\n",
        "\n",
        "        # Ingestion\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/municipalities\", schema=municipalities_schema)\n",
        "\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/municipalities\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Stop Spark if already running (prevents \"Only one SparkContext\" error)\n",
        "    try:\n",
        "        spark.stop()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Now initialize Spark\n",
        "    from pyspark.sql import SparkSession\n",
        "    spark = SparkSession.builder.master('local').appName('ETL Program').getOrCreate()\n",
        "\n",
        "    try:\n",
        "        print(\"Starting ETL program\")\n",
        "        etl = ETLTask(spark)\n",
        "\n",
        "        # Run all ingestion tasks\n",
        "        print(\"Running Task - Ingestion Vehicles\")\n",
        "        etl.ingestion_vehicles()\n",
        "\n",
        "        print(\"Running Task - Ingestion Lines\")\n",
        "        etl.ingestion_lines()\n",
        "\n",
        "        print(\"Running Task - Ingestion Municipalities\")\n",
        "        etl.ingestion_municipalities()\n",
        "\n",
        "        print(\"ETL program completed.\")\n",
        "\n",
        "        # Check results\n",
        "        print(\"Preview - vehicles (bronze)\")\n",
        "        spark.read.parquet(\"/content/lake/bronze/vehicles\").show(truncate=False)\n",
        "\n",
        "        print(\"Preview - lines (bronze)\")\n",
        "        spark.read.parquet(\"/content/lake/bronze/lines\").show(truncate=False)\n",
        "\n",
        "        print(\"Preview - municipalities (bronze)\")\n",
        "        spark.read.parquet(\"/content/lake/bronze/municipalities\").show(truncate=False)\n",
        "\n",
        "    finally:\n",
        "        # Clean up\n",
        "        spark.stop()"
      ],
      "metadata": {
        "id": "N5Z6-ipU-w5b",
        "outputId": "c6242b35-a03a-496f-a46d-0df9b899a581",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------+--------------+--------+---------+-------+----------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------------+----------+\n",
            "|bearing|block_id                      |current_status|id      |lat      |line_id|lon       |pattern_id|route_id|schedule_relationship|shift_id    |speed    |stop_id|timestamp          |trip_id                           |date      |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+----------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------------+----------+\n",
            "|64     |20250705-64020039-112090000007|STOPPED_AT    |44|12083|38.525925|4426   |-8.9100485|4426_0_1  |4426_0  |SCHEDULED            |112090000007|0.0      |160264 |2025-07-05 15:02:04|4426_0_1|1300|1600_PYPHK          |2025-07-05|\n",
            "|102    |20250705-64020292-121140000007|IN_TRANSIT_TO |44|12574|38.52944 |4512   |-8.8857765|4512_0_2  |4512_0  |SCHEDULED            |121140000007|0.0      |162008 |2025-07-05 15:01:51|4512_0_2|1300|1610_PYPHK          |2025-07-05|\n",
            "|85     |8_8216-23                     |IN_TRANSIT_TO |41|1124 |38.756638|1715   |-9.261184 |1715_1_2  |1715_1  |SCHEDULED            |8211        |8.888889 |170925 |2025-07-05 15:02:00|1715_1_2_1530_1559_0_8_21NBI      |2025-07-05|\n",
            "|167    |20250705-64020020-113090000007|IN_TRANSIT_TO |44|12679|38.53704 |4725   |-8.885865 |4725_0_2  |4725_0  |SCHEDULED            |113090000007|16.944445|162005 |2025-07-05 15:01:50|4725_0_2|1300|1600_PYPHK          |2025-07-05|\n",
            "|180    |20250705-64020064-121170000007|INCOMING_AT   |44|12606|38.56763 |4512   |-8.888023 |4512_0_1  |4512_0  |SCHEDULED            |121170000007|12.5     |130461 |2025-07-05 15:01:53|4512_0_1|1300|1500_PYPHK          |2025-07-05|\n",
            "|278    |20250705-64020252-123210000007|IN_TRANSIT_TO |44|12665|38.767635|4705   |-9.1038   |4705_0_1  |4705_0  |SCHEDULED            |123210000007|0.0      |100042 |2025-07-05 15:01:51|4705_0_1|1300|1600_PYPHK          |2025-07-05|\n",
            "|72     |20250705-64020138-111090000007|IN_TRANSIT_TO |44|12646|38.52874 |4901   |-8.886205 |4901_0_2  |4901_0  |SCHEDULED            |111090000007|5.8333335|160031 |2025-07-05 15:01:51|4901_0_2|1300|1600_PYPHK          |2025-07-05|\n",
            "|145    |20250705-64020280-121260000007|IN_TRANSIT_TO |44|12637|38.74544 |4001   |-8.948042 |4001_0_3  |4001_0  |SCHEDULED            |121260000007|7.2222223|019739 |2025-07-05 15:01:48|4001_0_3|1300|1530_PYPHK          |2025-07-05|\n",
            "|328    |20250705-64020046-111160000007|IN_TRANSIT_TO |44|12591|38.46833 |4470   |-9.027168 |4470_0_2  |4470_0  |SCHEDULED            |111160000007|11.666667|160798 |2025-07-05 15:01:50|4470_0_2|1300|1545_PYPHK          |2025-07-05|\n",
            "|138    |VER_SAB_VS2050                |IN_TRANSIT_TO |43|2244 |38.672066|3007   |-9.169583 |3007_0_1  |3007_0  |SCHEDULED            |VS2052      |10.277778|021062 |2025-07-05 15:01:38|3007_0_1_1530_1559_0_VER_SAB_G9Q68|2025-07-05|\n",
            "|23     |8_8033-23                     |IN_TRANSIT_TO |41|1149 |38.774185|1707   |-9.230444 |1707_0_1  |1707_0  |SCHEDULED            |8077        |8.333333 |030191 |2025-07-05 15:01:59|1707_0_1_1530_1559_0_8_21NBI      |2025-07-05|\n",
            "|40     |8_8212-23                     |IN_TRANSIT_TO |41|1363 |38.698154|1523   |-9.311459 |1523_0_2  |1523_0  |SCHEDULED            |8214        |7.7777777|121121 |2025-07-05 15:02:01|1523_0_2_1530_1559_0_8_21NBI      |2025-07-05|\n",
            "|142    |8_8731-23                     |INCOMING_AT   |41|1875 |38.782585|1205   |-9.33165  |1205_0_2  |1205_0  |SCHEDULED            |8775        |7.5      |170080 |2025-07-05 15:01:47|1205_0_2_1530_1559_0_8_21NBI      |2025-07-05|\n",
            "|356    |8_8034-23                     |IN_TRANSIT_TO |41|1357 |38.780205|1710   |-9.218555 |1710_3_2  |1710_3  |SCHEDULED            |8065        |7.5      |030814 |2025-07-05 15:01:08|1710_3_2_1530_1559_1_8_21NBI      |2025-07-05|\n",
            "|30     |8_8316-23                     |IN_TRANSIT_TO |41|1398 |38.751106|1615   |-9.338036 |1615_0_2  |1615_0  |SCHEDULED            |8310        |3.6111112|172260 |2025-07-05 15:01:37|1615_0_2_1500_1529_0_8_21NBI      |2025-07-05|\n",
            "|82     |VER_SAB_VS2062'_001           |INCOMING_AT   |43|2081 |38.654617|3023   |-9.164052 |3023_0_1  |3023_0  |SCHEDULED            |VS2083      |10.277778|020672 |2025-07-05 15:01:58|3023_0_1_1530_1559_0_VER_SAB_G9Q68|2025-07-05|\n",
            "|318    |4027-23'_001                  |IN_TRANSIT_TO |42|2350 |38.805687|2714   |-9.14261  |2714_0_2  |2714_0  |SCHEDULED            |4025        |7.2222223|071306 |2025-07-05 15:01:55|2714_0_2|2|3|1540_HUAG2           |2025-07-05|\n",
            "|38     |8_8048-23                     |STOPPED_AT    |41|1105 |38.7541  |1719   |-9.189807 |1719_0_2  |1719_0  |SCHEDULED            |8078        |1.9444444|060127 |2025-07-05 15:01:23|1719_0_2_1600_1629_0_8_21NBI      |2025-07-05|\n",
            "|0      |8_8627-23                     |STOPPED_AT    |41|1127 |38.7329  |1601   |-9.280665 |1601_1_1  |1601_1  |SCHEDULED            |8630        |0.0      |120559 |2025-07-05 15:01:40|1601_1_1_1530_1559_0_8_21NBI      |2025-07-05|\n",
            "|223    |4543-23                       |INCOMING_AT   |42|2211 |38.790047|2821   |-9.17634  |2821_0_1  |2821_0  |SCHEDULED            |4581        |7.7777777|110411 |2025-07-05 15:01:59|2821_0_1|2|3|1535_HUAG2           |2025-07-05|\n",
            "+-------+------------------------------+--------------+--------+---------+-------+----------+----------+--------+---------------------+------------+---------+-------+-------------------+----------------------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+----------+----+-------------------------------------------------------------------------+----------------------------------------------------------------------------------------+--------------+----------------------------------------+------------------------+----------+----------+\n",
            "|color  |facilities|id  |localities                                                               |long_name                                                                               |municipalities|patterns                                |routes                  |short_name|text_color|\n",
            "+-------+----------+----+-------------------------------------------------------------------------+----------------------------------------------------------------------------------------+--------------+----------------------------------------+------------------------+----------+----------+\n",
            "|#C61D23|[]        |1001|[Alfragide, Amadora, Reboleira, Buraca]                                  |Alfragide (Estr Seminario) - Reboleira (Estação)                                        |[1115]        |[1001_0_1, 1001_0_2]                    |[1001_0]                |1001      |#FFFFFF   |\n",
            "|#C61D23|[]        |1002|[Reboleira, Amadora, Atalaia, Alfragide]                                 |Reboleira (Estação) | Circular via Alfragide (Centro comercial ) e Amadora (Estação Sul)|[1115]        |[1002_0_3]                              |[1002_0]                |1002      |#FFFFFF   |\n",
            "|#C61D23|[]        |1003|[Amadora, Amadora Este]                                                  |Amadora (Estação Norte) - Amadora Este (Metro)                                          |[1115]        |[1003_0_1, 1003_0_2]                    |[1003_0]                |1003      |#FFFFFF   |\n",
            "|#C61D23|[]        |1004|[Amadora, Moinhos da Funcheira]                                          |Amadora (Estação Norte) via Moinhos da Funcheira | Circular                             |[1115]        |[1004_0_3]                              |[1004_0]                |1004      |#FFFFFF   |\n",
            "|#C61D23|[]        |1005|[Casal da Mira, Amadora]                                                 |Amadora (Estação Norte) - UBBO                                                          |[1115]        |[1005_0_2, 1005_0_1, 1005_1_2, 1005_2_3]|[1005_0, 1005_1, 1005_2]|1005      |#FFFFFF   |\n",
            "|#C61D23|[]        |1006|[Casal da Mira, Amadora, Moinhos da Funcheira]                           |Amadora (Estação Norte) - UBBO | Noturna                                                |[1115]        |[1006_0_2, 1006_0_1, 1006_1_1, 1006_1_2]|[1006_0, 1006_1]        |1006      |#FFFFFF   |\n",
            "|#3D85C6|[]        |1008|NULL                                                                     |Amadora Este (Metro) | Circular                                                         |[1115]        |[1008_0_3]                              |[1008_0]                |1008      |#FFFFFF   |\n",
            "|#3D85C6|[]        |1009|NULL                                                                     |Amadora (Hospital) Via Mina e Venteira | Circular                                       |[1115, 1111]  |[1009_0_3]                              |[1009_0]                |1009      |#FFFFFF   |\n",
            "|#C61D23|[]        |1010|[Amadora, Brandoa, Casal da Mira]                                        |Alfornelos (Metro) - Casal da Mira                                                      |[1115]        |[1010_0_2, 1010_0_1]                    |[1010_0]                |1010      |#FFFFFF   |\n",
            "|#C61D23|[]        |1011|[Brandoa, Amadora, Alfornelos, Reboleira]                                |Brandoa (Largo) - Reboleira (Metro)                                                     |[1115]        |[1011_0_1, 1011_0_2, 1011_1_3]          |[1011_0, 1011_1]        |1011      |#FFFFFF   |\n",
            "|#3D85C6|[]        |1012|[Amadora, Brandoa, Alfornelos]                                           |Alfornelos Metro via Brandoa | Circular                                                 |[1115]        |[1012_0_3]                              |[1012_0]                |1012      |#FFFFFF   |\n",
            "|#C61D23|[]        |1013|NULL                                                                     |Reboleira (Estação) - Urbanização Sky City via Casas do Lago                            |[1115]        |[1013_0_1, 1013_0_2]                    |[1013_0]                |1013      |#FFFFFF   |\n",
            "|#C61D23|[]        |1014|[Amadora, Reboleira, Mina de Água]                                       |Amadora (Cemitério) - Vila Chã via Casas do Lago                                        |[1115]        |[1014_0_1, 1014_0_2]                    |[1014_0]                |1014      |#FFFFFF   |\n",
            "|#3D85C6|[]        |1015|[Reboleira, Amadora, Atalaia]                                            |Reboleira (Estação) via Damaia | Circular                                               |[1115]        |[1015_0_3]                              |[1015_0]                |1015      |#FFFFFF   |\n",
            "|#C61D23|[]        |1101|[Alfragide, Oeiras, Linda-a-Velha, Algés, Carnaxide]                     |Alfragide (Centro Comercial) - Algés (Estação)                                          |[1110]        |[1101_0_1, 1101_0_2, 1101_1_1, 1101_1_2]|[1101_0, 1101_1]        |1101      |#FFFFFF   |\n",
            "|#C61D23|[]        |1103|[Algés, Oeiras, Queijas]                                                 |Algés (Estação) - Queijas (PSP)                                                         |[1110]        |[1103_0_1, 1103_0_2]                    |[1103_0]                |1103      |#FFFFFF   |\n",
            "|#3D85C6|[]        |1104|[Oeiras, Algés, Miraflores, Linda-a-Velha]                               |Algés | Circular via Centro Histórico                                                   |[1110]        |[1104_0_3]                              |[1104_0]                |1104      |#FFFFFF   |\n",
            "|#C61D23|[]        |1105|[Algés, Oeiras, Miraflores, Carnaxide, Queluz Baixo, Linda-a-Velha]      |Algés (Estação) - Queluz Baixo (Centro Comercial)                                       |[1110]        |[1105_0_1, 1105_0_2, 1105_1_1, 1105_1_2]|[1105_0, 1105_1]        |1105      |#FFFFFF   |\n",
            "|#C61D23|[]        |1106|[Queluz Baixo, Oeiras, Queijas, Cruz Quebrada, Algés, Alto da Boa Viagem]|Queluz Baixo (Centro Comercial) - Algés (Estação)                                       |[1110]        |[1106_0_2, 1106_1_2, 1106_1_1]          |[1106_0, 1106_1]        |1106      |#FFFFFF   |\n",
            "|#C61D23|[]        |1107|[Algés, Oeiras, Queluz Baixo, Queijas]                                   |Algés (Estação) - Queluz Baixo via Queijas                                              |[1110]        |[1107_0_1, 1107_0_2]                    |[1107_0]                |1107      |#FFFFFF   |\n",
            "+-------+----------+----+-------------------------------------------------------------------------+----------------------------------------------------------------------------------------+--------------+----------------------------------------+------------------------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------+-------------+----+----------------------+------+---------+----------------+\n",
            "|district_id|district_name|id  |name                  |prefix|region_id|region_name     |\n",
            "+-----------+-------------+----+----------------------+------+---------+----------------+\n",
            "|07         |Évora        |0712|Vendas Novas          |19    |PT187    |Alentejo Central|\n",
            "|11         |Lisboa       |1101|Alenquer              |20    |PT16B    |Oeste           |\n",
            "|11         |Lisboa       |1102|Arruda dos Vinhos     |20    |PT16B    |Oeste           |\n",
            "|11         |Lisboa       |1105|Cascais               |05    |PT170    |AML             |\n",
            "|11         |Lisboa       |1106|Lisboa                |06    |PT170    |AML             |\n",
            "|11         |Lisboa       |1107|Loures                |07    |PT170    |AML             |\n",
            "|11         |Lisboa       |1109|Mafra                 |08    |PT170    |AML             |\n",
            "|11         |Lisboa       |1110|Oeiras                |12    |PT170    |AML             |\n",
            "|11         |Lisboa       |1111|Sintra                |17    |PT170    |AML             |\n",
            "|11         |Lisboa       |1112|Sobral de Monte Agraço|20    |PT16B    |Oeste           |\n",
            "|11         |Lisboa       |1113|Torres Vedras         |20    |PT16B    |Oeste           |\n",
            "|11         |Lisboa       |1114|Vila Franca de Xira   |18    |PT170    |AML             |\n",
            "|11         |Lisboa       |1115|Amadora               |03    |PT170    |AML             |\n",
            "|11         |Lisboa       |1116|Odivelas              |11    |PT170    |AML             |\n",
            "|15         |Setúbal      |1502|Alcochete             |01    |PT170    |AML             |\n",
            "|15         |Setúbal      |1503|Almada                |02    |PT170    |AML             |\n",
            "|15         |Setúbal      |1504|Barreiro              |04    |PT170    |AML             |\n",
            "|15         |Setúbal      |1506|Moita                 |09    |PT170    |AML             |\n",
            "|15         |Setúbal      |1507|Montijo               |10    |PT170    |AML             |\n",
            "|15         |Setúbal      |1508|Palmela               |13    |PT170    |AML             |\n",
            "+-----------+-------------+----+----------------------+------+---------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}