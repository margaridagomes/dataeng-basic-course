{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/margaridagomes/dataeng-basic-course/blob/main/spark/challenges/challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOA_wQSmLd9z"
      },
      "source": [
        "# CHALLENGE 2\n",
        "##  Implement CLEANSING process\n",
        "- Set up path in the \"lake\"\n",
        "  - !mkdir -p /content/lake/silver\n",
        "\n",
        "- Read data from BRONZE layer as PARQUET:\n",
        "    - vehicles - path: /content/lake/bronze/vehicles\n",
        "    - lines - path: /content/lake/bronze/lines\n",
        "    - municipalities - path: /content/lake/bronze/municipalities\n",
        "\n",
        "- Transformations\n",
        "  - vehicles\n",
        "    - rename \"lat\" and \"lon\" to \"latitude\" and \"longitude\" respectively\n",
        "    - remove possible duplicates\n",
        "    - remove rows when the column CURRENT_STATUS is null\n",
        "    - remove any corrupted record\n",
        "  - lines\n",
        "    - remove duplicates\n",
        "    - remove rows when the column LONG_NAME is null\n",
        "    - remove any corrupted record\n",
        "  - municipalities\n",
        "    - remove duplicates\n",
        "    - remove rows when the columns NAME or DISTRICT_NAME are null\n",
        "    - remove any corrupted record\n",
        "\n",
        "- Write data as PARQUET into the SILVER layer (/content/lake/silver)\n",
        "  - Partition \"vehicles\" by \"date\"(created in the ingestion)\n",
        "  - Paths:\n",
        "    - vehicles - path: /content/lake/silver/vehicles\n",
        "    - lines - path: /content/lake/silver/lines\n",
        "    - municipalities - path: /content/lake/silver/municipalities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "c410e46c-4a50-43aa-926f-d0417c6280d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up path in the \"lake\"\n",
        "!mkdir -p /content/lake/bronze\n",
        "!mkdir -p /content/lake/silver\n",
        "\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "import requests\n",
        "\n",
        "class ETLFlow:\n",
        "    \"\"\"\n",
        "    Base ETL class with extraction and loading methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        self.spark = spark\n",
        "\n",
        "    def extract_from_api(self, url: str, schema: StructType = None) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Extract data from an API endpoint, returning a Spark DataFrame.\n",
        "        Applies schema if provided.\n",
        "        \"\"\"\n",
        "        response = requests.get(url)\n",
        "        rdd = spark.sparkContext.parallelize(response.json())\n",
        "        if schema:\n",
        "            df = spark.read.schema(schema).json(rdd)\n",
        "        else:\n",
        "            df = spark.read.json(rdd)\n",
        "        return df\n",
        "\n",
        "    def extract_from_file(self, format: str, path: str, **kwargs) -> DataFrame:\n",
        "        \"\"\"\n",
        "        Read data from file (e.g. Parquet) and return a DataFrame.\n",
        "        \"\"\"\n",
        "        df = self.spark.read.format(format).load(path)\n",
        "        return df\n",
        "\n",
        "    def load(self, df: DataFrame, format: str, path: str, partition_column: str = None, dynamic_partition_overwrite: bool = False, **kwargs) -> None:\n",
        "        \"\"\"\n",
        "        Save the DataFrame to the specified path in the chosen format.\n",
        "        If 'partition_column' is provided, partition the data accordingly.\n",
        "        If 'dynamic_partition_overwrite' is True, only overwrite the partitions present in the DataFrame.\n",
        "        \"\"\"\n",
        "        # Set Spark configuration for dynamic/static partition overwrite mode\n",
        "        if dynamic_partition_overwrite:\n",
        "            self.spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
        "        else:\n",
        "            self.spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"static\")\n",
        "\n",
        "        # Write the DataFrame as a single parquet file, with optional partitioning\n",
        "        if partition_column:\n",
        "            df.coalesce(1).write.mode(\"overwrite\").partitionBy(partition_column).format(format).save(path)\n",
        "        else:\n",
        "            df.coalesce(1).write.mode(\"overwrite\").format(format).save(path)\n",
        "\n",
        "class ETLTask(ETLFlow):\n",
        "    \"\"\"\n",
        "    ETL steps for lines, vehicles, and municipalities data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, spark: SparkSession) -> None:\n",
        "        self.spark = spark\n",
        "\n",
        "    def ingestion_lines(self):\n",
        "        \"\"\"\n",
        "        Extract 'lines' data from the API, enforce schema, and write as a single parquet file to bronze layer.\n",
        "        \"\"\"\n",
        "        # Schema definition for lines\n",
        "        lines_schema = StructType([StructField('color', StringType(), True),\n",
        "                                   StructField('facilities', ArrayType(StringType(), True), True),\n",
        "                                   StructField('id', StringType(), True),\n",
        "                                   StructField('localities', ArrayType(StringType(), True), True),\n",
        "                                   StructField('long_name', StringType(), True),\n",
        "                                   StructField('municipalities', ArrayType(StringType(), True), True),\n",
        "                                   StructField('patterns', ArrayType(StringType(), True), True),\n",
        "                                   StructField('routes', ArrayType(StringType(), True), True),\n",
        "                                   StructField('short_name', StringType(), True),\n",
        "                                   StructField('text_color', StringType(), True)])\n",
        "\n",
        "        # Ingestion\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/lines\", schema=lines_schema)\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/lines\")\n",
        "\n",
        "    def ingestion_vehicles(self):\n",
        "        \"\"\"\n",
        "        Extract 'vehicles' data from the API, enforce schema, add a partitioning 'date' column,\n",
        "        and write to bronze layer as a partitioned parquet file with dynamic partition overwrite enabled.\n",
        "        \"\"\"\n",
        "        # Schema definition for vehicles\n",
        "        vehicle_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                                  StructField('block_id', StringType(), True),\n",
        "                                  StructField('current_status', StringType(), True),\n",
        "                                  StructField('id', StringType(), True),\n",
        "                                  StructField('lat', FloatType(), True),\n",
        "                                  StructField('line_id', StringType(), True),\n",
        "                                  StructField('lon', FloatType(), True),\n",
        "                                  StructField('pattern_id', StringType(), True),\n",
        "                                  StructField('route_id', StringType(), True),\n",
        "                                  StructField('schedule_relationship', StringType(), True),\n",
        "                                  StructField('shift_id', StringType(), True),\n",
        "                                  StructField('speed', FloatType(), True),\n",
        "                                  StructField('stop_id', StringType(), True),\n",
        "                                  StructField('timestamp', TimestampType(), True),\n",
        "                                  StructField('trip_id', StringType(), True)])\n",
        "\n",
        "        # Ingestion\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/vehicles\", schema=vehicle_schema)\n",
        "\n",
        "        # Create \"date\" column from \"timestamp\"\n",
        "        df = df.withColumn(\"date\", F.expr(\"date(timestamp)\"))\n",
        "\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/vehicles\", partition_column=\"date\", dynamic_partition_overwrite=True)\n",
        "\n",
        "    def ingestion_municipalities(self):\n",
        "        \"\"\"\n",
        "        Extract municipalities data from API, enforce schema, write to bronze layer as a single parquet file.\n",
        "        \"\"\"\n",
        "        # Schema definition for municipalities\n",
        "        municipalities_schema = StructType([StructField('district_id', StringType(), True),\n",
        "                                            StructField('district_name', StringType(), True),\n",
        "                                            StructField('id', StringType(), True),\n",
        "                                            StructField('name', StringType(), True),\n",
        "                                            StructField('prefix', StringType(), True),\n",
        "                                            StructField('region_id', StringType(), True),\n",
        "                                            StructField('region_name', StringType(), True)])\n",
        "\n",
        "        # Ingestion\n",
        "        df = self.extract_from_api(url=\"https://api.carrismetropolitana.pt/municipalities\", schema=municipalities_schema)\n",
        "\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/bronze/municipalities\")\n",
        "\n",
        "    def cleansing_vehicles(self):\n",
        "        \"\"\"\n",
        "        Cleansing vehicles: rename lat/lon, remove duplicates, drop nulls and corrupted records, save to silver as a partitioned parquet file with dynamic partition overwrite enabled.\n",
        "        \"\"\"\n",
        "        # Ingestion\n",
        "        df = self.extract_from_file(format=\"parquet\", path=\"/content/lake/bronze/vehicles\")\n",
        "\n",
        "        # Renaming columns\n",
        "        df = df.withColumnRenamed(\"lat\", \"latitude\").withColumnRenamed(\"lon\", \"longitude\")\n",
        "\n",
        "        # Removing duplicates\n",
        "        df = df.dropDuplicates()\n",
        "\n",
        "        # Remove rows where 'current_status' is null\n",
        "        df = df.filter(F.col(\"current_status\").isNotNull())\n",
        "\n",
        "        # Remove corrupted records\n",
        "        if \"_corrupt_record\" in df.columns:\n",
        "          df = df.filter(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
        "\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/silver/vehicles\", partition_column=\"date\", dynamic_partition_overwrite=True)\n",
        "\n",
        "\n",
        "    def cleansing_lines(self):\n",
        "        \"\"\"\n",
        "        Cleansing lines: remove duplicates, drop nulls, remove corrupted records, save to silver.\n",
        "        \"\"\"\n",
        "        # Ingestion\n",
        "        df = self.extract_from_file(format=\"parquet\", path=\"/content/lake/bronze/lines\")\n",
        "\n",
        "        # Remove duplicates\n",
        "        df = df.dropDuplicates()\n",
        "\n",
        "        # Remove rows where 'long_name' is null\n",
        "        df = df.filter(F.col(\"long_name\").isNotNull())\n",
        "\n",
        "        # Remove corrupted records\n",
        "        if \"_corrupt_record\" in df.columns:\n",
        "          df = df.filter(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
        "\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/silver/lines\")\n",
        "\n",
        "\n",
        "    def cleansing_municipalities(self):\n",
        "        \"\"\"\n",
        "        Cleansing municipalities: remove duplicates, drop nulls, remove corrupted records, save to silver.\n",
        "        \"\"\"\n",
        "        # Ingestion\n",
        "        df = self.extract_from_file(format=\"parquet\", path=\"/content/lake/bronze/municipalities\")\n",
        "\n",
        "        # Remove duplicates\n",
        "        df = df.dropDuplicates()\n",
        "\n",
        "        # Remove rows where 'name' or 'district_name' is null\n",
        "        df = df.filter(F.col(\"name\").isNotNull() & F.col(\"district_name\").isNotNull())\n",
        "\n",
        "        # Remove corrupted records (records missing important columns)\n",
        "        if \"_corrupt_record\" in df.columns:\n",
        "          df = df.filter(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
        "\n",
        "        # Load\n",
        "        self.load(df=df, format=\"parquet\", path=\"/content/lake/silver/municipalities\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Stop Spark if already running (prevents \"Only one SparkContext\" error)\n",
        "    try:\n",
        "        spark.stop()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Now initialize Spark\n",
        "    from pyspark.sql import SparkSession\n",
        "    spark = SparkSession.builder.master('local').appName('ETL Program').getOrCreate()\n",
        "\n",
        "    try:\n",
        "        print(\"Starting ETL program\")\n",
        "        etl = ETLTask(spark)\n",
        "\n",
        "         # Run ingestion tasks (bronze layer)\n",
        "        print(\"Running Task - Ingestion Vehicles\")\n",
        "        etl.ingestion_vehicles()\n",
        "\n",
        "        print(\"Running Task - Ingestion Lines\")\n",
        "        etl.ingestion_lines()\n",
        "\n",
        "        print(\"Running Task - Ingestion Municipalities\")\n",
        "        etl.ingestion_municipalities()\n",
        "\n",
        "        # Run cleansing tasks (silver layer)\n",
        "        print(\"Running Task - Cleansing Vehicles\")\n",
        "        etl.cleansing_vehicles()\n",
        "\n",
        "        print(\"Running Task - Cleansing Lines\")\n",
        "        etl.cleansing_lines()\n",
        "\n",
        "        print(\"Running Task - Cleansing Municipalities\")\n",
        "        etl.cleansing_municipalities()\n",
        "\n",
        "        print(\"ETL program completed.\")\n",
        "\n",
        "        # Preview results in the silver layer\n",
        "        print(\"Preview - vehicles (silver)\")\n",
        "        spark.read.parquet(\"/content/lake/silver/vehicles\").show(truncate=False)\n",
        "\n",
        "        print(\"Preview - lines (silver)\")\n",
        "        spark.read.parquet(\"/content/lake/silver/lines\").show(truncate=False)\n",
        "\n",
        "        print(\"Preview - municipalities (silver)\")\n",
        "        spark.read.parquet(\"/content/lake/silver/municipalities\").show(truncate=False)\n",
        "\n",
        "    finally:\n",
        "        # Clean up\n",
        "        spark.stop()"
      ],
      "metadata": {
        "id": "I2snv1CEJU0l",
        "outputId": "339b06e1-c244-4790-97b8-4f91d35032b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+--------------------+---------+-------+-------------------+----------------------------------+----------+\n",
            "|bearing|block_id                      |current_status|id      |latitude |line_id|longitude|pattern_id|route_id|schedule_relationship|shift_id            |speed    |stop_id|timestamp          |trip_id                           |date      |\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+--------------------+---------+-------+-------------------+----------------------------------+----------+\n",
            "|126    |20250705-64020117-113170000007|IN_TRANSIT_TO |44|12677|38.58596 |4725   |-9.05523 |4725_0_1  |4725_0  |SCHEDULED            |113170000007        |27.5     |160027 |2025-07-05 15:40:42|4725_0_1|1300|1600_PYPHK          |2025-07-05|\n",
            "|279    |20250705-64020104-112190000007|IN_TRANSIT_TO |44|12061|38.528763|4441   |-8.884655|4441_0_2  |4441_0  |SCHEDULED            |112190000007        |3.0555556|160213 |2025-07-05 15:40:35|4441_0_2|1300|1630_PYPHK          |2025-07-05|\n",
            "|0      |8_8035-23                     |STOPPED_AT    |41|1346 |38.750435|1704   |-9.221872|1704_0_2  |1704_0  |SCHEDULED            |8035                |0.0      |030861 |2025-07-05 15:40:24|1704_0_2_1600_1629_0_8_21NBI      |2025-07-05|\n",
            "|22     |4070-23                       |IN_TRANSIT_TO |42|2408 |38.867622|2790   |-9.05844 |2790_0_2  |2790_0  |SCHEDULED            |4072                |7.7777777|180531 |2025-07-05 15:40:33|2790_0_2|2|3|1600_HUAG2           |2025-07-05|\n",
            "|248    |20250705-64020101-112340000007|IN_TRANSIT_TO |44|12066|38.532734|4403   |-8.890848|4403_0_2  |4403_0  |SCHEDULED            |112340000007        |10.277778|160090 |2025-07-05 15:40:41|4403_0_2|1300|1630_PYPHK          |2025-07-05|\n",
            "|40     |8_8305-23                     |INCOMING_AT   |41|1231 |38.751556|1622   |-9.348524|1622_0_1  |1622_0  |SCHEDULED            |8315                |8.611111 |172265 |2025-07-05 15:40:30|1622_0_1_1600_1629_0_8_21NBI      |2025-07-05|\n",
            "|77     |8_8007-23                     |STOPPED_AT    |41|1311 |38.778023|1707   |-9.224097|1707_0_1  |1707_0  |SCHEDULED            |8082                |0.0      |030271 |2025-07-05 15:40:05|1707_0_1_1600_1629_0_8_21NBI      |2025-07-05|\n",
            "|84     |20250705-64020173-112250000007|IN_TRANSIT_TO |44|12085|38.53013 |4440   |-8.877543|4440_0_2  |4440_0  |SCHEDULED            |112250000007        |5.0      |160430 |2025-07-05 15:40:31|4440_0_2|1300|1630_PYPHK          |2025-07-05|\n",
            "|71     |8_8904-23                     |IN_TRANSIT_TO |41|1312 |38.788143|1512   |-9.303979|1512_0_2  |1512_0  |SCHEDULED            |8904                |9.722222 |172082 |2025-07-05 15:40:19|1512_0_2_1600_1629_0_8_21NBI      |2025-07-05|\n",
            "|186    |1212                          |INCOMING_AT   |42|1212 |38.813717|2754   |-9.155673|2754_0_2  |2754_0  |SCHEDULED            |44297               |10.555555|070558 |2025-07-05 15:40:42|2754_0_2|160|3|1600_HUAG2         |2025-07-05|\n",
            "|334    |4728-23                       |INCOMING_AT   |42|2587 |38.904675|2750   |-9.190602|2750_0_2  |2750_0  |SCHEDULED            |4732                |11.944445|081097 |2025-07-05 15:40:39|2750_0_2|2|3|1540_HUAG2           |2025-07-05|\n",
            "|0      |VS_008                        |STOPPED_AT    |41|1220 |38.802822|1624   |-9.448811|1624_1_1  |1624_1  |SCHEDULED            |8711                |2.2222223|171343 |2025-07-05 15:40:42|1624_1_1_1530_1559_0_8_21NBI      |2025-07-05|\n",
            "|109    |VER_SAB_VS2019                |IN_TRANSIT_TO |43|2259 |38.667816|3011   |-9.164204|3011_0_2  |3011_0  |SCHEDULED            |VS2019              |4.4444447|020099 |2025-07-05 15:39:58|3011_0_2_1600_1629_0_VER_SAB_G9Q68|2025-07-05|\n",
            "|322    |4514-23                       |STOPPED_AT    |42|2205 |38.79042 |2821   |-9.175887|2821_0_2  |2821_0  |SCHEDULED            |4530                |1.9444444|110109 |2025-07-05 15:40:20|2821_0_2|2|3|1615_HUAG2           |2025-07-05|\n",
            "|0      |4018-23'_001                  |STOPPED_AT    |42|2338 |38.759422|2713   |-9.159253|2713_0_3  |2713_0  |SCHEDULED            |4116                |0.0      |060304 |2025-07-05 15:40:06|2713_0_3|2|3|1650_HUAG2           |2025-07-05|\n",
            "|143    |VER_SAB_VS1042                |IN_TRANSIT_TO |43|2210 |38.629093|3119   |-9.117233|3119_0_2  |3119_0  |SCHEDULED            |VS1024              |4.4444447|140218 |2025-07-05 15:40:40|3119_0_2_1600_1629_0_VER_SAB_G9Q68|2025-07-05|\n",
            "|181    |20250705-64020272-123120000007|IN_TRANSIT_TO |44|12657|38.774918|4702   |-9.105667|4702_0_2  |4702_0  |SCHEDULED            |123120000007        |0.0      |060005 |2025-07-05 15:40:39|4702_0_2|1300|1600_PYPHK          |2025-07-05|\n",
            "|341    |8_8727-23                     |IN_TRANSIT_TO |41|1390 |38.847435|1633   |-9.378221|1633_0_2  |1633_0  |SCHEDULED            |8727                |9.444445 |170025 |2025-07-05 15:40:16|1633_0_2_1600_1629_0_8_21NBI      |2025-07-05|\n",
            "|166    |8_8720-23                     |IN_TRANSIT_TO |41|541  |38.805866|1234   |-9.329548|1234_0_1  |1234_0  |SCHEDULED            |UNAVAILABLE_SHIFT_ID|6.111111 |170793 |2025-07-05 15:40:26|1234_0_1_1530_1559_0_8_21NBI      |2025-07-05|\n",
            "|172    |VER_SAB_VS2082                |IN_TRANSIT_TO |43|2225 |38.660603|3041   |-9.154791|3041_0_1  |3041_0  |SCHEDULED            |VS2071              |8.888889 |020679 |2025-07-05 15:40:42|3041_0_1_1630_1659_0_VER_SAB_G9Q68|2025-07-05|\n",
            "+-------+------------------------------+--------------+--------+---------+-------+---------+----------+--------+---------------------+--------------------+---------+-------+-------------------+----------------------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+----------+----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+------------------------+--------------------------------------------------------------------------------+--------------------------------+----------+----------+\n",
            "|color  |facilities|id  |localities                                                                                                                                                                                                                                                                          |long_name                                                                    |municipalities          |patterns                                                                        |routes                          |short_name|text_color|\n",
            "+-------+----------+----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+------------------------+--------------------------------------------------------------------------------+--------------------------------+----------+----------+\n",
            "|#3D85C6|[]        |1104|[Oeiras, Algés, Miraflores, Linda-a-Velha]                                                                                                                                                                                                                                          |Algés | Circular via Centro Histórico                                        |[1110]                  |[1104_0_3]                                                                      |[1104_0]                        |1104      |#FFFFFF   |\n",
            "|#C61D23|[]        |3119|[Pinhal de Cima, Seixal, Foros de Amora, Cruz de Pau, Amora, Fogueteiro, Marco Severino, Torre da Marinha, Arrentela, Cavaquinhas]                                                                                                                                                  |Pinhal Conde Cunha - Seixal (Terminal Fluvial)                               |[1510]                  |[3119_0_1, 3119_0_2]                                                            |[3119_0]                        |3119      |#FFFFFF   |\n",
            "|#C61D23|[]        |1117|[Caxias, Oeiras, Laveiras, Alto do Lagoal, Terrugem, Paço de Arcos, Lage]                                                                                                                                                                                                           |Caxias (Qta Moura) - Lage (Centro)                                           |[1110]                  |[1117_0_1, 1117_0_2, 1117_1_1, 1117_1_2, 1117_2_2, 1117_2_1, 1117_3_1, 1117_3_2]|[1117_0, 1117_1, 1117_2, 1117_3]|1117      |#FFFFFF   |\n",
            "|#C61D23|[]        |1733|[Marquês de Pombal, Lisboa, Queijas, Porto Salvo, Oeiras, Leião, Taguspark, São Marcos, Sintra]                                                                                                                                                                                     |Marquês Pombal (Metro) - São Marcos via Queijas (Rotunda) e Taguspark        |[1106, 1110, 1111]      |[1733_0_1, 1733_0_2, 1733_1_1, 1733_1_2, 1733_2_2]                              |[1733_0, 1733_1, 1733_2]        |1733      |#FFFFFF   |\n",
            "|#C61D23|[]        |2753|[Campo Grande, Odivelas, Loures, Sto. António dos Cavaleiros, Ponte Frielas, Mealhada, Mafra, Milharado, Senhor Roubado]                                                                                                                                                            |Lisboa (C. Grande) - Milharado (CASO) via Lousa                              |[1106, 1116, 1107, 1109]|[2753_0_1, 2753_0_2]                                                            |[2753_0]                        |2753      |#FFFFFF   |\n",
            "|#C61D23|[]        |4308|[Pinhal Novo, Vale Alecrim, Palmela, Batudes, Venda do Alcaide, Volta da Pedra]                                                                                                                                                                                                     |Palmela (Terminal) - Pinhal Novo (Estação)                                   |[1508]                  |[4308_0_2, 4308_0_1]                                                            |[4308_0]                        |4308      |#FFFFFF   |\n",
            "|#C61D23|[]        |4438|[Setúbal]                                                                                                                                                                                                                                                                           |Setúbal (Monte Belo Norte) - Setúbal (Saboaria)                              |[1512]                  |[4438_0_2, 4438_0_1, 4438_1_2, 4438_1_1]                                        |[4438_0, 4438_1]                |4438      |#FFFFFF   |\n",
            "|#C61D23|[]        |4452|[Setúbal, Praias do Sado, Santo Ovídio, Faralhão, Sto. Ovídio, Alto da Estefanilha, Mitrena]                                                                                                                                                                                        |Mitrena (Portucel) - Setúbal (ITS)                                           |[1512]                  |[4452_0_1, 4452_0_2, 4452_1_1, 4452_1_2]                                        |[4452_0, 4452_1]                |4452      |#FFFFFF   |\n",
            "|#C61D23|[]        |1103|[Algés, Oeiras, Queijas]                                                                                                                                                                                                                                                            |Algés (Estação) - Queijas (PSP)                                              |[1110]                  |[1103_0_1, 1103_0_2]                                                            |[1103_0]                        |1103      |#FFFFFF   |\n",
            "|#C61D23|[]        |2116|[Mafra, Murgueira]                                                                                                                                                                                                                                                                  |Encarnação - Mafra (Parque Desportivo)                                       |[1109]                  |[2116_0_1, 2116_0_2]                                                            |[2116_0]                        |2116      |#FFFFFF   |\n",
            "|#FDB71A|[]        |2741|[Campo Grande, Loures, Mafra, Venda do Pinheiro, Malveira, Alcainça, Antas]                                                                                                                                                                                                         |Ericeira (Terminal) - Lisboa (C. Grande) via Ericeira (Centro) Freixeira e A8|[1106, 1107, 1109]      |[2741_1_2, 2741_1_1, 2741_0_2, 2741_0_1]                                        |[2741_1, 2741_0]                |2741      |#FFFFFF   |\n",
            "|#C61D23|[]        |3549|[Quinta do Conde, Sesimbra, Seixal, Fernão Ferro, Fontaínhas, Marco Grilo, Carrasqueira, Quintinhas, Cotovia, Santana, Sampaio]                                                                                                                                                     |Quinta do Conde - Sesimbra (Terminal) via Sampaio e Marco do Grilo           |[1511, 1510]            |[3549_0_1, 3549_0_2]                                                            |[3549_0]                        |3549      |#FFFFFF   |\n",
            "|#3D85C6|[]        |4106|[Moita, Alhos Vedros, Arroteias]                                                                                                                                                                                                                                                    |Alhos Vedros | Circular via Centro de Saúde                                  |[1506]                  |[4106_0_3]                                                                      |[4106_0]                        |4106      |#FFFFFF   |\n",
            "|#C61D23|[]        |4541|[Algeruz, Brejos do Assa, Palmela, Setúbal]                                                                                                                                                                                                                                         |Algeruz - Setúbal (Av. Luísa Todi)                                           |[1508, 1512]            |[4541_0_1, 4541_0_2]                                                            |[4541_0]                        |4541      |#FFFFFF   |\n",
            "|#C61D23|[]        |4550|[Vila Nogueira de Azeitão, Vila Fresca de Azeitão, Vendas de Azeitão, Setúbal, São Gonçalo, Cabanas, Quinta do Anjo, Palmela]                                                                                                                                                       |Palmela (Terminal) - Vila Nogueira de Azeitão                                |[1512, 1508]            |[4550_0_2, 4550_0_1]                                                            |[4550_0]                        |4550      |#FFFFFF   |\n",
            "|#C61D23|[]        |1208|[Almargem do Bispo, Sintra, Vale de Lobos, Algueirão - Mem Martins, Portela de Sintra, Algueirão-Mem Martins]                                                                                                                                                                       |Almargem Bispo (Cemitério) - Portela de Sintra (Estação Norte) via Hospital  |[1111]                  |[1208_0_1, 1208_0_2]                                                            |[1208_0]                        |1208      |#FFFFFF   |\n",
            "|#C61D23|[]        |1631|[Estoril, Cascais, Alcabideche, Alcoitão, Ribeira da Penha Longa, Bº da Cadeia do Linhó, Linhó, Sintra, Mem Martins, Rio de Mouro]                                                                                                                                                  |Estoril (Estação) - Rio De Mouro (Estação Sul)                               |[1105, 1111]            |[1631_0_1, 1631_0_2]                                                            |[1631_0]                        |1631      |#FFFFFF   |\n",
            "|#C61D23|[]        |3527|[Torre da Caparica, Monte da Caparica, Bairro Fundo Fomento, Almada, Vale Mourelos, Feijó, Vale Flores, Corroios, Seixal, Sta. Marta do Pinhal, Sta. Marta de Corroios, Muxito, Cruz de Pau, Paivas, Marco Severino, Fogueteiro, Torre da Marinha, Cavadas, Farinheiras, Paio Pires]|Monte de Caparica (FCT) - Paio Pires (Bairro Cucena)                         |[1503, 1510]            |[3527_0_1, 3527_0_2, 3527_1_1, 3527_1_2]                                        |[3527_0, 3527_1]                |3527      |#FFFFFF   |\n",
            "|#C61D23|[]        |1220|[Cacém, Sintra, Taguspark, São Marcos]                                                                                                                                                                                                                                              |Agualva-Cacém (Estação) via S. Marcos (Largo) | Circular                     |[1111]                  |[1220_0_3]                                                                      |[1220_0]                        |1220      |#FFFFFF   |\n",
            "|#C61D23|[]        |1245|[Portela de Sintra, Sintra, Terrugem]                                                                                                                                                                                                                                               |Catribana (Largo) - Portela Sintra (Estação Norte)                           |[1111]                  |[1245_0_2, 1245_0_1]                                                            |[1245_0]                        |1245      |#FFFFFF   |\n",
            "+-------+----------+----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+------------------------+--------------------------------------------------------------------------------+--------------------------------+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----------+-------------+----+-------------------+------+---------+----------------+\n",
            "|district_id|district_name|id  |name               |prefix|region_id|region_name     |\n",
            "+-----------+-------------+----+-------------------+------+---------+----------------+\n",
            "|11         |Lisboa       |1107|Loures             |07    |PT170    |AML             |\n",
            "|15         |Setúbal      |1504|Barreiro           |04    |PT170    |AML             |\n",
            "|11         |Lisboa       |1101|Alenquer           |20    |PT16B    |Oeste           |\n",
            "|15         |Setúbal      |1511|Sesimbra           |15    |PT170    |AML             |\n",
            "|07         |Évora        |0712|Vendas Novas       |19    |PT187    |Alentejo Central|\n",
            "|11         |Lisboa       |1102|Arruda dos Vinhos  |20    |PT16B    |Oeste           |\n",
            "|15         |Setúbal      |1510|Seixal             |14    |PT170    |AML             |\n",
            "|11         |Lisboa       |1114|Vila Franca de Xira|18    |PT170    |AML             |\n",
            "|15         |Setúbal      |1506|Moita              |09    |PT170    |AML             |\n",
            "|11         |Lisboa       |1115|Amadora            |03    |PT170    |AML             |\n",
            "|15         |Setúbal      |1512|Setúbal            |16    |PT170    |AML             |\n",
            "|11         |Lisboa       |1109|Mafra              |08    |PT170    |AML             |\n",
            "|11         |Lisboa       |1113|Torres Vedras      |20    |PT16B    |Oeste           |\n",
            "|15         |Setúbal      |1503|Almada             |02    |PT170    |AML             |\n",
            "|11         |Lisboa       |1110|Oeiras             |12    |PT170    |AML             |\n",
            "|11         |Lisboa       |1111|Sintra             |17    |PT170    |AML             |\n",
            "|15         |Setúbal      |1508|Palmela            |13    |PT170    |AML             |\n",
            "|11         |Lisboa       |1105|Cascais            |05    |PT170    |AML             |\n",
            "|11         |Lisboa       |1116|Odivelas           |11    |PT170    |AML             |\n",
            "|15         |Setúbal      |1502|Alcochete          |01    |PT170    |AML             |\n",
            "+-----------+-------------+----+-------------------+------+---------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}